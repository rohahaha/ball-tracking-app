import cv2
import numpy as np
import streamlit as st
from collections import deque
import plotly.graph_objs as go
import pandas as pd
from scipy.signal import savgol_filter
import colorsys
import tempfile
import os
import gdown
import traceback
import urllib.request
import time
from streamlit_plotly_events import plotly_events  # ì¶”ê°€ëœ import
from streamlit_image_coordinates import streamlit_image_coordinates

# Streamlit í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ë‹¤ë¥¸ st ëª…ë ¹ì–´ë³´ë‹¤ ë¨¼ì € ì™€ì•¼ í•¨)
st.set_page_config(
    page_title="ê°ì²´ íƒì§€ ë° ì†ë„ ë¶„ì„ê¸°",
    page_icon="ğŸ¾",
    layout="wide",
    initial_sidebar_state="auto",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': 'Ball Tracking and Energy Analysis Application'
    }
)

# ì•± ì‹œì‘ ë¶€ë¶„ì— CSS ì¶”ê°€
st.markdown("""
    <style>
    .stVideo {
        max-width: 384px !important;
    }
    .main {
        background-color: #f0f2f6;
        padding: 2rem;
    }
    .st-emotion-cache-1v0mbdj img {
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    </style>
    """, unsafe_allow_html=True)

# ì•± ì œëª©
st.title('ê°ì²´ íƒì§€ ë° ì†ë„ ì¶”ì  í”„ë¡œê·¸ë¨_by ROHA')

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - ì—¬ê¸°ì— í•„ìš”í•œ ë³€ìˆ˜ë“¤ ì¶”ê°€
if 'initialized' not in st.session_state:
    st.session_state.initialized = False
    st.session_state.analysis_frames = []
    st.session_state.analysis_speeds = []
    st.session_state.analysis_images = {}
    st.session_state.analysis_positions = {}
    st.session_state.selected_frame = None
    st.session_state.video_settings = {}  # video_settingsë„ ì¶”ê°€
    
# ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬
try:
    if not st.session_state.initialized:
        st.session_state.initialized = True
        # ì—¬ê¸°ì— ì´ˆê¸°í™” ì½”ë“œ ì¶”ê°€
except Exception as e:
    st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# YOLO íŒŒì¼ ê²½ë¡œ ì„¤ì • (URLì€ ì œê±°í•˜ê³  ë‹¨ìˆœí™”)
YOLO_DIR = "yolo"
YOLO_FILES = {
    "yolov4.cfg": "https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg",
    "coco.names": "https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names"
}
WEIGHTS_FILE_ID = "1XWTMChKOcrVpo-uaIldGp6bRzBfYIGqJ"
WEIGHTS_FILENAME = "yolov4.weights"

def create_yolov4_cfg():
    """YOLOv4 ì„¤ì • íŒŒì¼ ìƒì„±"""
    cfg_content = """[net]
batch=64
subdivisions=16
width=608
height=608
channels=3
momentum=0.949
decay=0.0005
angle=0
saturation=1.5
exposure=1.5
hue=.1
learning_rate=0.00261
burn_in=1000
max_batches=500500
policy=steps
steps=400000,450000
scales=.1,.1
mosaic=1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[route]
layers=-2

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[route]
layers=-1,-7

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[route]
layers=-2

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[route]
layers=-1,-10

[maxpool]
stride=1
size=13

[route]
layers=-1,-3,-5,-6

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers=85

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]
layers=-1,-3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers=54

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers=-1,-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear

[yolo]
mask=0,1,2
anchors=12,16,19,36,40,28,36,75,76,55,72,146,142,110,192,243,459,401
classes=80
num=9
jitter=.3
ignore_thresh=.7
truth_thresh=1
scale_x_y=1.2
iou_thresh=0.213
nms_kind=greedynms
beta_nms=0.6
max_delta=5

[route]
layers=-4

[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=256
activation=leaky

[route]
layers=-1,-16

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear

[yolo]
mask=3,4,5
anchors=12,16,19,36,40,28,36,75,76,55,72,146,142,110,192,243,459,401
classes=80
num=9
jitter=.3
ignore_thresh=.7
truth_thresh=1
scale_x_y=1.1
iou_thresh=0.213
nms_kind=greedynms
beta_nms=0.6
max_delta=5

[route]
layers=-4

[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=512
activation=leaky

[route]
layers=-1,-37

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear

[yolo]
mask=6,7,8
anchors=12,16,19,36,40,28,36,75,76,55,72,146,142,110,192,243,459,401
classes=80
num=9
jitter=.3
ignore_thresh=.7
truth_thresh=1
scale_x_y=1.05
iou_thresh=0.213
nms_kind=greedynms
beta_nms=0.6
max_delta=5"""
    return cfg_content.strip()

def save_yolov4_cfg():
    """YOLOv4 ì„¤ì • íŒŒì¼ ì €ì¥"""
    try:
        os.makedirs(YOLO_DIR, exist_ok=True)
        cfg_path = os.path.join(YOLO_DIR, "yolov4.cfg")
        
        # ë¨¼ì € URLì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹œë„
        try:
            st.info("Downloading YOLOv4 config from source...")
            response = urllib.request.urlopen(YOLO_FILES["yolov4.cfg"])
            cfg_content = response.read().decode('utf-8')
            
            with open(cfg_path, 'w', newline='\n') as f:
                f.write(cfg_content)
            
            if os.path.exists(cfg_path):
                file_size = os.path.getsize(cfg_path)
                if file_size > 10 * 1024:  # 10KB ì´ìƒ
                    st.success(f"Downloaded YOLOv4 configuration file (size: {file_size/1024:.1f}KB)")
                    return True
                
        except Exception as e:
            st.warning(f"Failed to download config file: {str(e)}. Trying backup method...")
        
        # ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë°±ì—… URL ì‹œë„
        backup_url = "https://github.com/AlexeyAB/darknet/raw/master/cfg/yolov4.cfg"
        try:
            st.info("Trying backup source for YOLOv4 config...")
            response = urllib.request.urlopen(backup_url)
            cfg_content = response.read().decode('utf-8')
            
            with open(cfg_path, 'w', newline='\n') as f:
                f.write(cfg_content)
            
            if os.path.exists(cfg_path):
                file_size = os.path.getsize(cfg_path)
                if file_size > 10 * 1024:  # 10KB ì´ìƒ
                    st.success(f"Downloaded YOLOv4 configuration file from backup (size: {file_size/1024:.1f}KB)")
                    return True
                
        except Exception as e:
            st.warning(f"Failed to download from backup: {str(e)}. Using local template...")
        
        # ëª¨ë“  ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ í…œí”Œë¦¿ ì‚¬ìš©
        cfg_content = create_yolov4_cfg()
        with open(cfg_path, 'w', newline='\n') as f:
            f.write(cfg_content)
        
        if os.path.exists(cfg_path):
            file_size = os.path.getsize(cfg_path)
            if file_size > 10 * 1024:  # 10KB ì´ìƒ
                st.success(f"Created YOLOv4 configuration file using template (size: {file_size/1024:.1f}KB)")
                return True
            else:
                st.error(f"Created file is too small: {file_size/1024:.1f}KB")
                if os.path.exists(cfg_path):
                    os.remove(cfg_path)
                return False
        
        st.error("Failed to create valid YOLOv4 configuration file")
        if os.path.exists(cfg_path):
            os.remove(cfg_path)
        return False
        
    except Exception as e:
        st.error(f"Error handling YOLOv4 configuration file: {str(e)}")
        if 'cfg_path' in locals() and os.path.exists(cfg_path):
            os.remove(cfg_path)
        return False

def download_yolo_files():
    """YOLO ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        os.makedirs(YOLO_DIR, exist_ok=True)
        
        # YOLOv4 cfg íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        if not os.path.exists(os.path.join(YOLO_DIR, "yolov4.cfg")):
            st.info("Creating YOLOv4 configuration file...")
            if not save_yolov4_cfg():
                return False
        
        # coco.names íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        names_path = os.path.join(YOLO_DIR, "coco.names")
        if not os.path.exists(names_path):
            st.info("Downloading coco.names...")
            try:
                urllib.request.urlretrieve(YOLO_FILES["coco.names"], names_path)
                st.success("Downloaded coco.names")
            except Exception as e:
                st.error(f"Error downloading coco.names: {str(e)}")
                return False
        
        # weights íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        weights_path = os.path.join(YOLO_DIR, WEIGHTS_FILENAME)
        if not os.path.exists(weights_path):
            with st.spinner("Downloading YOLOv4 weights from Google Drive... This may take a few minutes..."):
                try:
                    output = gdown.download(
                        f"https://drive.google.com/uc?id={WEIGHTS_FILE_ID}",
                        weights_path,
                        quiet=False
                    )
                    if output is not None and os.path.exists(weights_path):
                        file_size = os.path.getsize(weights_path) / (1024 * 1024)  # MBë¡œ ë³€í™˜
                        if file_size > 200:  # ìµœì†Œ 200MB
                            st.success(f"Successfully downloaded YOLOv4 weights! (File size: {file_size:.1f} MB)")
                        else:
                            st.error("Downloaded weights file appears to be incomplete")
                            if os.path.exists(weights_path):
                                os.remove(weights_path)
                            return False
                    else:
                        st.error("Failed to download weights file")
                        return False
                except Exception as e:
                    st.error(f"Error downloading weights file: {str(e)}")
                    if os.path.exists(weights_path):
                        os.remove(weights_path)
                    return False
        
        # ëª¨ë“  íŒŒì¼ ê²€ì¦
        return verify_yolo_files()
    
    except Exception as e:
        st.error(f"Error in download process: {str(e)}")
        return False

def verify_yolo_files():
    """YOLO íŒŒì¼ë“¤ì˜ ì¡´ì¬ ì—¬ë¶€ì™€ ë¬´ê²°ì„± í™•ì¸"""
    required_files = {
        "yolov4.cfg": 10 * 1024,     # ìµœì†Œ 10KB
        "coco.names": 0.5 * 1024,    # ìµœì†Œ 0.5KB (ìˆ˜ì •ë¨)
        "yolov4.weights": 200 * 1024 * 1024  # ìµœì†Œ 200MB
    }
    
    try:
        for filename, min_size in required_files.items():
            filepath = os.path.join(YOLO_DIR, filename)
            if not os.path.exists(filepath):
                st.warning(f"Missing required file: {filename}")
                return False
            
            file_size = os.path.getsize(filepath)
            if file_size < min_size:
                st.warning(f"File {filename} appears to be incomplete (size: {file_size/1024:.1f}KB, required: {min_size/1024:.1f}KB)")
                return False
            else:
                st.success(f"Verified {filename} (size: {file_size/1024:.1f}KB)")
        
        return True
    except Exception as e:
        st.error(f"Error during file verification: {str(e)}")
        return False

def initialize_yolo():
    """YOLO ëª¨ë¸ ì´ˆê¸°í™”"""
    try:
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not verify_yolo_files():
            st.warning("YOLO ëª¨ë¸ íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            if st.button("YOLO íŒŒì¼ ë‹¤ìš´ë¡œë“œ"):
                if not download_yolo_files():
                    st.error("íŒŒì¼ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return None, None, None

        # íŒŒì¼ì´ ìˆìœ¼ë©´ ëª¨ë¸ ë¡œë“œ ì‹œì‘
        weights_path = os.path.join(YOLO_DIR, WEIGHTS_FILENAME)
        cfg_path = os.path.join(YOLO_DIR, "yolov4.cfg")
        names_path = os.path.join(YOLO_DIR, "coco.names")
        
        with st.spinner("YOLO ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            try:
                net = cv2.dnn.readNet(weights_path, cfg_path)
                if net is None:
                    raise Exception("Failed to load YOLO network")
                
                layer_names = net.getLayerNames()
                unconnected_layers = net.getUnconnectedOutLayers()
                
                if isinstance(unconnected_layers, np.ndarray):
                    output_layers = [layer_names[i - 1] for i in unconnected_layers.flatten()]
                elif isinstance(unconnected_layers, list):
                    output_layers = [layer_names[int(i[0]) - 1] if isinstance(i, (list, np.ndarray)) 
                                   else layer_names[int(i) - 1] for i in unconnected_layers]
                else:
                    output_layers = [layer_names[int(unconnected_layers) - 1]]
                
                with open(names_path, "r") as f:
                    classes = [line.strip() for line in f.readlines()]
                
                st.success("YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                return net, output_layers, classes
                
            except Exception as e:
                st.error(f"YOLO ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return None, None, None
            
    except Exception as e:
        st.error(f"YOLO ëª¨ë¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return None, None, None

def create_stable_tracker():
    """ë‹¨ìˆœí™”ëœ íŠ¸ë˜ì»¤ ìƒì„±"""
    try:
        class SimpleTracker:
            def __init__(self):
                self.bbox = None
                self.last_center = None
                
            def init(self, frame, bbox):
                self.bbox = tuple(map(int, bbox))
                self.last_center = (
                    int(bbox[0] + bbox[2]/2),
                    int(bbox[1] + bbox[3]/2)
                )
                return True
                
            def update(self, frame):
                if self.bbox is None:
                    return False, None
                
                # HSV ìƒ‰ìƒ ê¸°ë°˜ ì¶”ì  ì‹œë„
                try:
                    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                    x, y, w, h = self.bbox
                    
                    # í˜„ì¬ ë°•ìŠ¤ ì˜ì—­ì˜ HSV í‰ê· ê°’ ê³„ì‚°
                    roi = hsv[y:y+h, x:x+w]
                    avg_hue = np.mean(roi[:,:,0])
                    
                    # HSV ë²”ìœ„ ì„¤ì •
                    lower = np.array([max(0, avg_hue-10), 50, 50])
                    upper = np.array([min(180, avg_hue+10), 255, 255])
                    
                    # ë§ˆìŠ¤í¬ ìƒì„±
                    mask = cv2.inRange(hsv, lower, upper)
                    mask = cv2.erode(mask, None, iterations=2)
                    mask = cv2.dilate(mask, None, iterations=2)
                    
                    # ì»¨íˆ¬ì–´ ì°¾ê¸°
                    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    if contours:
                        c = max(contours, key=cv2.contourArea)
                        ((x, y), radius) = cv2.minEnclosingCircle(c)
                        M = cv2.moments(c)
                        
                        if M["m00"] != 0:
                            center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
                            self.last_center = center
                            self.bbox = (
                                int(center[0] - self.bbox[2]/2),
                                int(center[1] - self.bbox[3]/2),
                                self.bbox[2],
                                self.bbox[3]
                            )
                            return True, self.bbox
                            
                except Exception:
                    pass
                
                # ì¶”ì  ì‹¤íŒ¨ ì‹œ ì´ì „ ìœ„ì¹˜ ë°˜í™˜
                return True, self.bbox
        
        tracker = SimpleTracker()
        st.success("ë‹¨ìˆœ íŠ¸ë˜ì»¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return tracker
        
    except Exception as e:
        st.error(f"íŠ¸ë˜ì»¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None
        
def detect_ball(frame, lower_color, upper_color, min_radius, max_radius):
    """ìƒ‰ìƒ ê¸°ë°˜ ê³µ ê²€ì¶œ"""
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, lower_color, upper_color)
    
    mask = cv2.erode(mask, None, iterations=2)
    mask = cv2.dilate(mask, None, iterations=2)
    
    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    center = None
    
    if len(contours) > 0:
        c = max(contours, key=cv2.contourArea)
        ((x, y), radius) = cv2.minEnclosingCircle(c)
        M = cv2.moments(c)
        if M["m00"] != 0:
            center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
        
        if min_radius < radius < max_radius:
            return (int(x), int(y), int(radius)), center
    
    return None, None

def track_ball(frame, tracker, bbox, lower_color, upper_color, min_radius, max_radius):
    """ê³µ ì¶”ì  í•¨ìˆ˜ - ì¤‘ì‹¬ì  ê²€ì¶œ ê°œì„ """
    # ìƒ‰ìƒ ê¸°ë°˜ ê³µ ê²€ì¶œ
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, lower_color, upper_color)
    
    # ë…¸ì´ì¦ˆ ì œê±°
    mask = cv2.erode(mask, None, iterations=2)
    mask = cv2.dilate(mask, None, iterations=2)
    
    # ì»¨íˆ¬ì–´ ì°¾ê¸°
    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    center = None
    
    if len(contours) > 0:
        # ê°€ì¥ í° ì»¨íˆ¬ì–´ ì°¾ê¸°
        c = max(contours, key=cv2.contourArea)
        ((x, y), radius) = cv2.minEnclosingCircle(c)
        
        # ëª¨ë©˜íŠ¸ë¥¼ ì´ìš©í•œ ì¤‘ì‹¬ì  ê³„ì‚°
        M = cv2.moments(c)
        if M["m00"] != 0:
            center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
            
            if min_radius < radius < max_radius:
                # ì› ê·¸ë¦¬ê¸°
                cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 0), 2)
                cv2.circle(frame, center, 5, (0, 0, 255), -1)
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì—…ë°ì´íŠ¸
                bbox_size = int(radius * 2)
                bbox = (
                    int(center[0] - bbox_size/2),
                    int(center[1] - bbox_size/2),
                    bbox_size,
                    bbox_size
                )
                tracker.init(frame, bbox)
    
    # íŠ¸ë˜ì»¤ ì—…ë°ì´íŠ¸
    if center is None:
        success, box = tracker.update(frame)
        if success:
            (x, y, w, h) = [int(v) for v in box]
            center = (x + w//2, y + h//2)
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.circle(frame, center, 5, (0, 0, 255), -1)
            bbox = (x, y, w, h)
    
    return frame, center, bbox

def calculate_frame_speed(positions_queue, fps, pixels_per_meter):
    """ê°œë³„ í”„ë ˆì„ì˜ ì†ë„ ê³„ì‚°"""
    try:
        first_frame, first_pos = positions_queue[0]
        last_frame, last_pos = positions_queue[-1]
        
        time_diff = (last_frame - first_frame) / fps
        if time_diff <= 0:
            return None
            
        distance = np.sqrt(
            (last_pos[0] - first_pos[0])**2 + 
            (last_pos[1] - first_pos[1])**2
        )
        
        distance_meters = (distance / pixels_per_meter) * 0.5
        speed = distance_meters / time_diff
        
        # ë¹„ì •ìƒì ì¸ ì†ë„ í•„í„°ë§
        return speed if speed <= 50 else None
        
    except Exception:
        return None
        
def calculate_filtered_speed(speed_queue, speeds):
    """ì†ë„ í•„í„°ë§ ë° í‰ê·  ê³„ì‚°"""
    try:
        avg_speed = sum(speed_queue) / len(speed_queue)
        
        # ê¸‰ê²©í•œ ì†ë„ ë³€í™” í•„í„°ë§
        if speeds and abs(avg_speed - speeds[-1]) > 10:
            return speeds[-1]
            
        return avg_speed
        
    except Exception:
        return speeds[-1] if speeds else 0

def is_significant_frame(current_speed, speeds):
    """ì¤‘ìš” í”„ë ˆì„ íŒë‹¨ (ìµœê³ /ìµœì € ì†ë„ ë“±)"""
    if not speeds:
        return True
    
    return (
        abs(current_speed - speeds[-1]) > 2 or  # ê¸‰ê²©í•œ ì†ë„ ë³€í™”
        current_speed > max(speeds) or  # ìµœê³  ì†ë„
        current_speed < min(speeds)  # ìµœì € ì†ë„
    )


def rgb_to_hsv(r, g, b):
    """RGB to HSV ë³€í™˜"""
    r, g, b = r/255.0, g/255.0, b/255.0
    h, s, v = colorsys.rgb_to_hsv(r, g, b)
    return int(h * 179), int(s * 255), int(v * 255)

def update_charts(frames, speeds, speed_chart, frame_count, graph_color, 
                 is_final=False, frame_images=None, ball_positions=None, fps=30):
    """ì°¨íŠ¸ ì—…ë°ì´íŠ¸ - ë””ìŠ¤í”Œë ˆì´ ìˆ˜ì •"""
    try:
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        avg_speed = np.mean(speeds)
        max_speed = np.max(speeds)
        min_speed = np.min(speeds)
        total_time = max([frame/fps for frame in frames])
        
        if is_final:
            # í†µê³„ í‘œì‹œ
            st.markdown("### ì „ì²´ í†µê³„")
            cols = st.columns(4)
            with cols[0]:
                st.metric("í‰ê·  ì†ë„", f"{avg_speed:.2f} m/s")
            with cols[1]:
                st.metric("ìµœëŒ€ ì†ë„", f"{max_speed:.2f} m/s")
            with cols[2]:
                st.metric("ìµœì†Œ ì†ë„", f"{min_speed:.2f} m/s")
            with cols[3]:
                st.metric("ì´ ë¶„ì„ ì‹œê°„", f"{total_time:.2f} s")

            # ê·¸ë˜í”„ì™€ ì´ë¯¸ì§€ë¥¼ ìœ„í•œ ì—´ ìƒì„±
            graph_col, images_col = st.columns([2, 1])
            
            with graph_col:
                # ê·¸ë˜í”„ ìƒì„±
                fig = go.Figure()
                
                # ë©”ì¸ ì†ë„ ë¼ì¸
                fig.add_trace(go.Scatter(
                    x=[frame/fps for frame in frames],
                    y=speeds,
                    mode='lines+markers',
                    name='Speed (m/s)',
                    line=dict(
                        color=graph_color,
                        width=2
                    ),
                    marker=dict(
                        size=4
                    ),
                    hovertemplate='Time: %{x:.2f}s<br>Speed: %{y:.2f} m/s<extra></extra>'
                ))
                
                # ë ˆì´ì•„ì›ƒ ì„¤ì •
                fig.update_layout(
                    title="Ball Speed Analysis",
                    xaxis_title="Time (s)",
                    yaxis_title="Speed (m/s)",
                    plot_bgcolor='white',
                    paper_bgcolor='white',
                    font=dict(color='black'),
                    showlegend=True,
                    height=500,
                    xaxis=dict(
                        showgrid=True,
                        gridcolor='lightgrey',
                        showline=True,
                        linewidth=1,
                        linecolor='black'
                    ),
                    yaxis=dict(
                        showgrid=True,
                        gridcolor='lightgrey',
                        showline=True,
                        linewidth=1,
                        linecolor='black',
                        range=[0, max_speed * 1.1]  # yì¶• ë²”ìœ„ ì„¤ì •
                    )
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # CSV ë‹¤ìš´ë¡œë“œ
                df = pd.DataFrame({
                    'Time (s)': [frame/fps for frame in frames],
                    'Frame': frames,
                    'Speed (m/s)': speeds
                })
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "ì†ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                    csv,
                    "ball_speed_data.csv",
                    "text/csv",
                    key='download-csv-results'
                )
            
            with images_col:
                # ìµœê³ /ìµœì € ì†ë„ í”„ë ˆì„ ì°¾ê¸°
                max_speed_indices = [i for i, s in enumerate(speeds) if abs(s - max_speed) < 0.01]
                min_speed_indices = [i for i, s in enumerate(speeds) if abs(s - min_speed) < 0.01]
                
                if max_speed_indices and frame_images:
                    st.markdown(f"#### ìµœê³  ì†ë„: {max_speed:.2f} m/s")
                    for idx in max_speed_indices[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€
                        frame_num = frames[idx]
                        if frame_num in frame_images:
                            st.markdown(f"ì‹œê°„: {frame_num/fps:.2f}ì´ˆ")
                            st.image(frame_images[frame_num], channels="BGR", use_column_width=True)
                
                if min_speed_indices and frame_images:
                    st.markdown(f"#### ìµœì € ì†ë„: {min_speed:.2f} m/s")
                    for idx in min_speed_indices[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€
                        frame_num = frames[idx]
                        if frame_num in frame_images:
                            st.markdown(f"ì‹œê°„: {frame_num/fps:.2f}ì´ˆ")
                            st.image(frame_images[frame_num], channels="BGR", use_column_width=True)
        
        else:
            # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ìš© ê°„ë‹¨í•œ ê·¸ë˜í”„
            last_100_frames = frames[-100:]
            last_100_speeds = speeds[-100:]
            
            fig = go.Figure(go.Scatter(
                x=[frame/fps for frame in last_100_frames],
                y=last_100_speeds,
                mode='lines+markers',
                line=dict(color=graph_color)
            ))
            fig.update_layout(
                title="Real-time Speed",
                xaxis_title="Time (s)",
                yaxis_title="Speed (m/s)",
                height=300
            )
            speed_chart.plotly_chart(fig, use_container_width=True)
            
    except Exception as e:
        st.error(f"ì°¨íŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.error(traceback.format_exc())


def show_frame_analysis(frame_num, frames, speeds, images, positions):
    """í”„ë ˆì„ ë¶„ì„ í‘œì‹œ - m/s ë‹¨ìœ„ë¡œ ìˆ˜ì •"""
    available_frames = sorted(list(images.keys()))
    nearest_frame = min(available_frames, key=lambda x: abs(x - frame_num))
    
    if nearest_frame in images:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"#### Frame {nearest_frame}")
            current_speed = speeds[frames.index(nearest_frame)]
            frame_image = images[nearest_frame]
            st.image(frame_image, channels="BGR", 
                    caption=f"Speed: {current_speed:.2f} m/s")
            
            # ì†ë„ ë¶„ì„
            st.markdown("#### ì†ë„ ë¶„ì„")
            avg_speed = np.mean(speeds)
            max_speed = np.max(speeds)
            speed_diff = current_speed - avg_speed
            
            st.write(f"- í˜„ì¬ ì†ë„: {current_speed:.2f} m/s")
            st.write(f"- í‰ê·  ëŒ€ë¹„: {speed_diff:+.2f} m/s")
            st.write(f"- ìµœëŒ€ ëŒ€ë¹„: {(current_speed/max_speed*100):.1f}%")
        
        with col2:
            st.markdown("#### ê³µì˜ ê¶¤ì ")
            trajectory_img = images[nearest_frame].copy()
            
            for i in range(max(0, nearest_frame-5), min(nearest_frame+6, max(frames)+1)):
                if i in positions:
                    pos = positions[i]
                    color = (0, 255, 0) if i < nearest_frame else\
                           (0, 0, 255) if i > nearest_frame else\
                           (255, 0, 0)
                    cv2.circle(trajectory_img, pos, 3, color, -1)
            
            st.image(trajectory_img, channels="BGR", 
                    caption="Green: Past, Red: Current, Blue: Future")
            
            if nearest_frame in positions:
                x, y = positions[nearest_frame]
                st.write(f"- ê³µì˜ ìœ„ì¹˜: ({x}, {y}) pixels")

    # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    df = pd.DataFrame({
        'Frame': frames,
        'Speed (km/h)': speeds
    })
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button(
        "ì†ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
        csv,
        "ball_speed_data.csv",
        "text/csv",
        key='download-csv-results'
    )

def select_color_from_image(frame):
    """ì´ë¯¸ì§€ì—ì„œ í´ë¦­ìœ¼ë¡œ ìƒ‰ìƒ ì„ íƒ"""
    if 'color_selected' not in st.session_state:
        st.session_state.color_selected = False

    st.write("ì•„ë˜ ì´ë¯¸ì§€ë¥¼ ë§ˆìš°ìŠ¤ë¡œ í´ë¦­í•˜ì—¬ ê³µì˜ ìƒ‰ìƒì„ ì„ íƒí•˜ì„¸ìš”.")
    
    # BGRì—ì„œ RGBë¡œ ë³€í™˜
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    height, width = frame.shape[:2]
    
    # ìƒíƒœ ì´ˆê¸°í™”
    if 'click_x' not in st.session_state:
        st.session_state.click_x = width // 2
    if 'click_y' not in st.session_state:
        st.session_state.click_y = height // 2
    if 'selected_color' not in st.session_state:
        st.session_state.selected_color = None
    if 'lower_color' not in st.session_state:
        st.session_state.lower_color = None
    if 'upper_color' not in st.session_state:
        st.session_state.upper_color = None
    if 'color_tolerance' not in st.session_state:
        st.session_state.color_tolerance = 20

    col1, col2 = st.columns([3, 1])
    
    with col1:
        from streamlit_image_coordinates import streamlit_image_coordinates
        
        frame_display = frame_rgb.copy()
        if st.session_state.selected_color is not None:
            # ì´ì „ ì„ íƒ ìœ„ì¹˜ í‘œì‹œ
            x, y = st.session_state.click_x, st.session_state.click_y
            marker_size = 10
            cv2.line(frame_display, (x - marker_size, y), (x + marker_size, y), (0, 255, 0), 2)
            cv2.line(frame_display, (x, y - marker_size), (x, y + marker_size), (0, 255, 0), 2)
        
        clicked_coords = streamlit_image_coordinates(
            frame_display,
            key="color_picker"
        )
        
        if clicked_coords:
            x, y = clicked_coords["x"], clicked_coords["y"]
            st.session_state.click_x = x
            st.session_state.click_y = y
            st.session_state.selected_color = frame[y, x]
            
            # í˜„ì¬ ì„ íƒ ìœ„ì¹˜ í‘œì‹œ
            frame_with_marker = frame_rgb.copy()
            marker_size = 10
            cv2.line(frame_with_marker, (x - marker_size, y), (x + marker_size, y), (0, 255, 0), 2)
            cv2.line(frame_with_marker, (x, y - marker_size), (x, y + marker_size), (0, 255, 0), 2)
            st.image(frame_with_marker, caption="í´ë¦­í•˜ì—¬ ìƒ‰ìƒ ì„ íƒ", use_column_width=True)

    with col2:
        if st.session_state.selected_color is not None:
            b, g, r = st.session_state.selected_color
            st.write("ì„ íƒí•œ ìƒ‰ìƒ:")
            color_display = np.zeros((100, 100, 3), dtype=np.uint8)
            color_display[:] = (r, g, b)
            st.image(color_display)
            
            h, s, v = rgb_to_hsv(r, g, b)
            st.session_state.color_tolerance = st.slider(
                "ìƒ‰ìƒ í—ˆìš© ë²”ìœ„", 
                0, 50, 
                st.session_state.color_tolerance
            )
            
            # HSV ìƒ‰ìƒ ë²”ìœ„ ì—…ë°ì´íŠ¸
            st.session_state.lower_color = np.array([
                max(0, h - st.session_state.color_tolerance), 
                max(0, s - 50), 
                max(0, v - 50)
            ])
            st.session_state.upper_color = np.array([
                min(179, h + st.session_state.color_tolerance), 
                min(255, s + 50), 
                min(255, v + 50)
            ])
            
            # ë§ˆìŠ¤í¬ ë¯¸ë¦¬ë³´ê¸°
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            mask = cv2.inRange(hsv, st.session_state.lower_color, st.session_state.upper_color)
            mask_preview = cv2.bitwise_and(frame, frame, mask=mask)
            mask_preview_rgb = cv2.cvtColor(mask_preview, cv2.COLOR_BGR2RGB)
            st.image(mask_preview_rgb, caption="ë§ˆìŠ¤í¬ ë¯¸ë¦¬ë³´ê¸°")
            
            # BGR, HSV ê°’ í‘œì‹œ
            st.write(f"BGR ê°’: ({b}, {g}, {r})")
            st.write(f"HSV ê°’: ({h}, {s}, {v})")
            
            # ìƒ‰ìƒ ì„ íƒ í™•ì • ë²„íŠ¼
            if st.button("ì´ ìƒ‰ìƒìœ¼ë¡œ ì„ íƒ"):
                st.session_state.color_selected = True
                return (tuple(st.session_state.selected_color), 
                        st.session_state.lower_color, 
                        st.session_state.upper_color, 
                        (st.session_state.click_x, st.session_state.click_y))

    if st.session_state.color_selected:
        return (tuple(st.session_state.selected_color), 
                st.session_state.lower_color, 
                st.session_state.upper_color, 
                (st.session_state.click_x, st.session_state.click_y))
    
    return None, None, None, None

def detect_ball_with_yolo(frame, net, output_layers, classes):
    """YOLOë¥¼ ì‚¬ìš©í•œ ê³µ ê²€ì¶œ"""
    try:
        height, width = frame.shape[:2]
        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
        
        net.setInput(blob)
        outs = net.forward(output_layers)

        best_confidence = 0
        best_box = None

        for out in outs:
            for detection in out:
                scores = detection[5:]
                class_id = np.argmax(scores)
                confidence = scores[class_id]

                if confidence > 0.5:  # ê¸°ì¤€ê°’ ìˆ˜ì • ê°€ëŠ¥
                    try:
                        class_name = classes[class_id]
                        if class_name == "sports ball" and confidence > best_confidence:
                            center_x = int(detection[0] * width)
                            center_y = int(detection[1] * height)
                            w = int(detection[2] * width)
                            h = int(detection[3] * height)

                            x = int(center_x - w / 2)
                            y = int(center_y - h / 2)
                            
                            # ë²”ìœ„ ê²€ì‚¬ ì¶”ê°€
                            x = max(0, min(x, width - w))
                            y = max(0, min(y, height - h))
                            w = min(w, width - x)
                            h = min(h, height - y)

                            best_box = (x, y, w, h)
                            best_confidence = confidence
                    except IndexError:
                        continue

        if best_box is not None:
            st.success(f"YOLOê°€ ê³µì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤! (ì‹ ë¢°ë„: {best_confidence:.2f})")
            return best_box
        return None  # ê²½ê³  ë©”ì‹œì§€ ì œê±°
            
    except Exception as e:
        st.error(f"YOLO ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
        

def resize_frame(frame, target_width=384):
    """ì˜ìƒì˜ ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì•ˆì „í•˜ê²Œ í¬ê¸° ì¡°ì •"""
    try:
        if frame is None:
            return None
            
        height, width = frame.shape[:2]
        if width == 0 or height == 0:
            return frame
            
        # ì¢…íš¡ë¹„ ê³„ì‚°
        aspect_ratio = float(width) / float(height)
        
        # ìƒˆë¡œìš´ ë†’ì´ ê³„ì‚°
        target_height = int(round(target_width / aspect_ratio))
        
        # ìµœì†Œ í¬ê¸° ë³´ì¥
        if target_height < 1:
            target_height = 1
        
        # ë¦¬ì‚¬ì´ì¦ˆ ìˆ˜í–‰
        resized = cv2.resize(frame, (target_width, target_height), 
                           interpolation=cv2.INTER_LINEAR)
        
        return resized
        
    except Exception as e:
        st.error(f"í”„ë ˆì„ ë¦¬ì‚¬ì´ì¦ˆ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return frame  # ì˜¤ë¥˜ ë°œìƒì‹œ ì›ë³¸ ë°˜í™˜

def process_video(video_path, initial_bbox, pixels_per_meter, net, output_layers, 
                 classes, lower_color, upper_color, graph_color):
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ë¶„ì„ - ê°œì„ ëœ ë²„ì „"""
    try:
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ìœˆë„ìš° í¬ê¸° ì„¤ì •
        MEMORY_WINDOW = 300  # ì €ì¥í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
        frame_images = {}
        ball_positions = {}
        
        video = None
        try:
            video = cv2.VideoCapture(video_path)
            if not video.isOpened():
                raise ValueError("ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
            fps = video.get(cv2.CAP_PROP_FPS)
            total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # Streamlit ë ˆì´ì•„ì›ƒ ì„¤ì •
            col1, col2 = st.columns([2, 1])
            
            with col1:
                video_frame = st.empty()
            with col2:
                real_time_speed = st.empty()
                speed_chart = st.empty()

            frames = []
            speeds = []
            
            # íŠ¸ë˜ì»¤ ì´ˆê¸°í™”
            tracker = create_stable_tracker()
            if tracker is None:
                raise ValueError("íŠ¸ë˜ì»¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # ì†ë„ ê³„ì‚°ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
            speed_queue = deque(maxlen=5)
            positions_queue = deque(maxlen=5)
            frame_count = 0
            
            # ì§„í–‰ ìƒíƒœ í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„
            while True:
                ret, frame = video.read()
                if not ret:
                    break
                    
                try:
                    # ë©”ëª¨ë¦¬ ê´€ë¦¬: ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±°
                    if frame_count > MEMORY_WINDOW:
                        old_frame = frame_count - MEMORY_WINDOW
                        if old_frame in frame_images:
                            del frame_images[old_frame]
                        if old_frame in ball_positions:
                            del ball_positions[old_frame]
                    
                    frame = resize_frame(frame)
                    if frame is None:
                        raise ValueError("í”„ë ˆì„ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨")
                        
                    processed_frame, center, bbox = track_ball(
                        frame, tracker, bbox, lower_color, upper_color, 10, 50
                    )
                    
                    if center:
                        positions_queue.append((frame_count, center))
                        
                        if len(positions_queue) >= 2:
                            # ì†ë„ ê³„ì‚° ë° í•„í„°ë§
                            speed = calculate_frame_speed(
                                positions_queue, fps, pixels_per_meter
                            )
                            
                            if speed is not None:
                                speed_queue.append(speed)
                                avg_speed = calculate_filtered_speed(speed_queue, speeds)
                                
                                speeds.append(avg_speed)
                                frames.append(frame_count)
                                ball_positions[frame_count] = center
                                
                                # ì¤‘ìš” í”„ë ˆì„ë§Œ ì €ì¥
                                if is_significant_frame(avg_speed, speeds):
                                    frame_images[frame_count] = processed_frame.copy()
                                
                                real_time_speed.markdown(
                                    f"### Current Speed\n{avg_speed:.2f} m/s"
                                )
                    
                    video_frame.image(processed_frame, channels="BGR", use_column_width=False)
                    
                except Exception as e:
                    st.warning(f"í”„ë ˆì„ {frame_count} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                frame_count += 1
                progress = int((frame_count / total_frames) * 100)
                progress_bar.progress(progress)
                status_text.text(f"ì²˜ë¦¬ ì¤‘: {frame_count}/{total_frames} í”„ë ˆì„ ({progress}%)")
                
            # ê²°ê³¼ ë¶„ì„ ë° í‘œì‹œ
            if speeds:
                update_charts(frames, speeds, speed_chart, frame_count,
                            graph_color, is_final=True,
                            frame_images=frame_images,
                            ball_positions=ball_positions,
                            fps=fps)
            else:
                st.warning("ì†ë„ ë°ì´í„°ê°€ ê¸°ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if video is not None:
                video.release()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            frame_images.clear()
            ball_positions.clear()
            
    except Exception as e:
        st.error(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.error(traceback.format_exc())
        
def process_uploaded_video(uploaded_file, net, output_layers, classes):
    """ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ ì²˜ë¦¬"""
    try:
        if 'video_settings' not in st.session_state:
            st.session_state.video_settings = {}

        # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì²˜ë¦¬
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
            tfile.write(uploaded_file.read())
            video_path = tfile.name
            
            try:
                video = cv2.VideoCapture(video_path)
                ret, first_frame = video.read()
                video.release()
                
                if not ret or first_frame is None:
                    st.error("ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return
                    
                # ì²« í”„ë ˆì„ í¬ê¸° ì¡°ì •
                first_frame = resize_frame(first_frame)
                if first_frame is None:
                    st.error("í”„ë ˆì„ ì²˜ë¦¬ ì‹¤íŒ¨")
                    return
                    
                st.video(video_path)
                
                height, width = first_frame.shape[:2]
                
                # ê·¸ë˜í”„ ì„¤ì •
                graph_color = st.radio(
                    "ê·¸ë˜í”„ ìƒ‰ìƒ:",
                    ('white', 'black'),
                    key='graph_color'
                )
                
                # ìƒ‰ìƒ ì„ íƒ
                selected_color, lower_color, upper_color, click_pos = select_color_from_image(first_frame)
                if not any([selected_color is None, lower_color is None, upper_color is None, click_pos is None]):
                    # video settings ì—…ë°ì´íŠ¸
                    st.session_state.video_settings.update({
                        'selected_color': selected_color,
                        'lower_color': lower_color,
                        'upper_color': upper_color,
                        'click_pos': click_pos,
                        'graph_color': graph_color
                    })
                    
                    if all(k in st.session_state.video_settings for k in 
                          ['selected_color', 'lower_color', 'upper_color', 'click_pos']):
                        # ê±°ë¦¬ ì¸¡ì •ì„ ìœ„í•œ ì  ì„ íƒ
                        settings_col1, settings_col2 = st.columns(2)
                        
                        with settings_col1:
                            x1 = st.slider('ì²« ë²ˆì§¸ ì  X ì¢Œí‘œ', 0, width, 
                                st.session_state.video_settings.get('x1', width // 4))
                            y1 = st.slider('ì²« ë²ˆì§¸ ì  Y ì¢Œí‘œ', 0, height, 
                                st.session_state.video_settings.get('y1', height // 2))
                        
                        with settings_col2:
                            x2 = st.slider('ë‘ ë²ˆì§¸ ì  X ì¢Œí‘œ', 0, width, 
                                st.session_state.video_settings.get('x2', 3 * width // 4))
                            y2 = st.slider('ë‘ ë²ˆì§¸ ì  Y ì¢Œí‘œ', 0, height, 
                                st.session_state.video_settings.get('y2', height // 2))
                        
                        # í”„ë ˆì„ì— ì •ë³´ í‘œì‹œ
                        frame_with_info = first_frame.copy()
                        cv2.circle(frame_with_info, (x1, y1), 5, (0, 255, 0), -1)
                        cv2.circle(frame_with_info, (x2, y2), 5, (0, 255, 0), -1)
                        cv2.line(frame_with_info, (x1, y1), (x2, y2), (0, 255, 0), 2)
                        
                        # ì„ íƒí•œ ìƒ‰ìƒ ìœ„ì¹˜ í‘œì‹œ
                        click_x, click_y = st.session_state.video_settings['click_pos']
                        selected_color = st.session_state.video_settings['selected_color']
                        bbox_size = 50
                        bbox_x = max(0, click_x - bbox_size//2)
                        bbox_y = max(0, click_y - bbox_size//2)
                        bbox_w = min(bbox_size, width - bbox_x)
                        bbox_h = min(bbox_size, height - bbox_y)
                        
                        cv2.rectangle(frame_with_info, (bbox_x, bbox_y), 
                                    (bbox_x + bbox_w, bbox_y + bbox_h), (0, 255, 255), 2)
                        cv2.circle(frame_with_info, (click_x, click_y), 5, tuple(map(int, selected_color)), -1)
                        
                        st.image(frame_with_info, channels="BGR", use_column_width=False)
                        
                        # ì‹¤ì œ ê±°ë¦¬ ì…ë ¥
                        real_distance = st.number_input(
                            "ì„ íƒí•œ ë‘ ì  ì‚¬ì´ì˜ ì‹¤ì œ ê±°ë¦¬(ë¯¸í„°)ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:", 
                            min_value=0.1, 
                            value=st.session_state.video_settings.get('real_distance', 1.0), 
                            step=0.1
                        )
                        
                        # ì„¤ì •ê°’ ì €ì¥
                        st.session_state.video_settings.update({
                            'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                            'real_distance': real_distance
                        })
                        
                        # pixels_per_meter ê³„ì‚°
                        pixel_distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
                        pixels_per_meter = pixel_distance / real_distance
                        st.write(f"ê³„ì‚°ëœ pixels_per_meter: {pixels_per_meter:.2f}")
                        
                        # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
                        if st.button('ì˜ìƒ ë‚´ ê³µ ì¶”ì  ë° ë¶„ì„ ì‹œì‘í•˜ê¸°'):
                            initial_bbox = (bbox_x, bbox_y, bbox_w, bbox_h)
                            st.write("Processing video...")
                            try:
                                process_video(video_path, initial_bbox, pixels_per_meter, 
                                           net, output_layers, classes, 
                                           st.session_state.video_settings['lower_color'],
                                           st.session_state.video_settings['upper_color'],
                                           st.session_state.video_settings['graph_color'])
                            except Exception as e:
                                st.error(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                st.error(traceback.format_exc())
                    else:
                        st.warning("ìƒ‰ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        
            finally:
                if 'video' in locals():
                    video.release()
                try:
                    os.unlink(video_path)
                except:
                    pass
                    
    except Exception as e:
        st.error(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.error(traceback.format_exc())
        
def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ê°œì„ """
    try:
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'initialized' not in st.session_state:
            st.session_state.initialized = False
            st.session_state.analysis_frames = []
            st.session_state.analysis_speeds = []
            st.session_state.analysis_images = {}
            st.session_state.analysis_positions = {}
            st.session_state.selected_frame = None
            st.session_state.video_settings = {}
            
        # YOLO ëª¨ë¸ ì´ˆê¸°í™”
        net, output_layers, classes = initialize_yolo()
        if not all([net, output_layers, classes]):
            st.error("YOLO ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return

        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", 
            type=['mp4', 'avi', 'mov'],
            key='video_upload'
        )
        
        if uploaded_file is not None:
            # ì„ì‹œ íŒŒì¼ ì²˜ë¦¬
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
                try:
                    tfile.write(uploaded_file.read())
                    process_uploaded_video(tfile.name, net, output_layers, classes)
                finally:
                    try:
                        os.unlink(tfile.name)
                    except:
                        pass
                        
    except Exception as e:
        st.error(f"ì–´í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.error(traceback.format_exc())
        
if __name__ == "__main__":
    main()
